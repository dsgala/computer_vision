{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ n_1 = \\frac{1}{1 \\ + \\ exp(-W_1^{T}x)} $\n",
    "\n",
    "$ n_2 = \\frac{1}{1 \\ + \\ exp(-W_2^{T}n_1)} $\n",
    "\n",
    "$n_3 = \\frac{1}{1 \\ + \\ exp(-W_3^{T}n_2)} $\n",
    "\n",
    "$\\hat{y} = \\frac{1}{1 \\ + \\ exp(-W_4^{T}n_3)} $\n",
    "\n",
    "$ \\frac {d\\hat{y}}{dx} =  \\frac {d\\hat{y}}{dn_3} .  \\frac {dn_3}{dn_2} . \\frac  {dn_2}{dn_1} . \\frac {dn_1}{dx} $\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$ \\frac{d\\hat{y}}{dn_3} = \\hat{y}. (1-\\hat{y}) . W_4 $\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def net (x,w):\n",
    "    \"\"\"\n",
    "    A simple neural net that performs non linear transformation\n",
    "    Funtion : 1 / (1+e^(-w*x))\n",
    "    x: inputs\n",
    "    w: weight matrix\n",
    "    Returns the function value\n",
    "    \"\"\"\n",
    "    return 1/(1+np.exp(-x.dot(w)))\n",
    "\n",
    "\n",
    "\n",
    "def compute_loss(y,y_pred):\n",
    "    \"\"\"\n",
    "    Loss function : sum(y_pred**2 - y**2)\n",
    "    y: ground truth targets\n",
    "    y_pred: predicted target values\n",
    "    \"\"\"\n",
    "    return np.mean((y_pred - y)**2)\n",
    "\n",
    "def backprop_outer(y,y_pred,w,x):\n",
    "    \"\"\"\n",
    "    Backpropogation to compute gradients of weights\n",
    "    y:ground truth targets\n",
    "    y_pred: predicted targets\n",
    "    w: weights for the network\n",
    "    x:inputs to the net\n",
    "    \"\"\"\n",
    "    # start from outer most\n",
    "    y_grad = 2.0 * (y_pred - y)\n",
    "    #inner layer grads\n",
    "    w_grad = x.T.dot(y_grad * y_pred * (1-y_pred))\n",
    "    return w_grad\n",
    "\n",
    "def backprop_inner(nu,nd):\n",
    "    \"\"\"\n",
    "    Backpropogation to compute gradients of weights\n",
    "    y:ground truth targets\n",
    "    y_pred: predicted targets\n",
    "    w: weights for the network\n",
    "    x:inputs to the net\n",
    "    \"\"\"\n",
    "\n",
    "    #inner layer grads\n",
    "    wi_grad = nd.T.dot( nu * (1-nu))\n",
    "    return wi_grad\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 4)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-13-8068ea0c0133>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;31m#initialize the weight matrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 12\u001b[0;31m \u001b[0mw1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mw4\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim_x\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdim_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"Loss\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 4)"
     ]
    }
   ],
   "source": [
    "dim_x=1000 #input dims\n",
    "dim_y=2 #output dims\n",
    "batch = 10000 #batch size for training\n",
    "lr = 1e-3 #learning rate for weight update\n",
    "steps =  5000 #steps for learning\n",
    "\n",
    "#create random input and targets\n",
    "x=np.random.randn(batch,dim_x)\n",
    "y=np.random.randn(batch, dim_y)\n",
    "\n",
    "#initialize the weight matrix\n",
    "w1 =np.random.randn(dim_x,dim_y)\n",
    "w2 =np.random.randn(dim_x,dim_y)\n",
    "w3 =np.random.randn(dim_x,dim_y)\n",
    "w4 =np.random.randn(dim_x,dim_y)\n",
    "\n",
    "columns=[\"Loss\"]\n",
    "Loss = pd.DataFrame(columns=[\"Loss\"])\n",
    "\n",
    "for i in range(steps):\n",
    "    #feed forward process\n",
    "    n1 = net(x,w1)\n",
    "    n2 = net(n1,w2)\n",
    "    n3 = net(n2,w3)\n",
    "    y_pred = net(n3,w4)\n",
    "    #compute loss\n",
    "    loss = compute_loss(y, y_pred)\n",
    "    Loss.loc[i]=[loss]\n",
    "    print(\"Loss: \",loss, \"at step:\",i)\n",
    "    #compute grads using backprop on given net\n",
    "    w_grad = backprop_outer(y,y_pred,w,x)\n",
    "    #update weights with some learning rate\n",
    "    w -= lr * w_grad\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pd.DataFrame(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1226.665879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1224.564926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1224.636741</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1224.636472</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1224.514040</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1224.355683</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>1224.356192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1224.235349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>1224.216470</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1224.258288</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>1224.143721</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>1224.178955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>1224.133709</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>1224.075160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>1224.135140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>1223.875479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>1223.893606</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>1223.812248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>1223.782566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>1223.717322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>1223.529330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>1223.726450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>1223.720750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>1223.579304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>1223.529050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>1223.627680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>1223.454270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>1223.420681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>1223.326355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>1223.385662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4970</th>\n",
       "      <td>1218.549393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4971</th>\n",
       "      <td>1218.549386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4972</th>\n",
       "      <td>1218.549393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>1218.549381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4974</th>\n",
       "      <td>1218.549386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4975</th>\n",
       "      <td>1218.549385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4976</th>\n",
       "      <td>1218.549386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4977</th>\n",
       "      <td>1218.549372</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4978</th>\n",
       "      <td>1218.549380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4979</th>\n",
       "      <td>1218.549392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4980</th>\n",
       "      <td>1218.549380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4981</th>\n",
       "      <td>1218.549387</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4982</th>\n",
       "      <td>1218.549392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4983</th>\n",
       "      <td>1218.549388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4984</th>\n",
       "      <td>1218.549388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4985</th>\n",
       "      <td>1218.549382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4986</th>\n",
       "      <td>1218.549388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4987</th>\n",
       "      <td>1218.549376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4988</th>\n",
       "      <td>1218.549381</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4989</th>\n",
       "      <td>1218.549389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4990</th>\n",
       "      <td>1218.549375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4991</th>\n",
       "      <td>1218.549390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4992</th>\n",
       "      <td>1218.549386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4993</th>\n",
       "      <td>1218.549389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4994</th>\n",
       "      <td>1218.549384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4995</th>\n",
       "      <td>1218.549390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4996</th>\n",
       "      <td>1218.549389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4997</th>\n",
       "      <td>1218.549385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4998</th>\n",
       "      <td>1218.549389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4999</th>\n",
       "      <td>1218.549385</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows Ã— 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Loss\n",
       "0     1226.665879\n",
       "1     1224.564926\n",
       "2     1224.636741\n",
       "3     1224.636472\n",
       "4     1224.514040\n",
       "5     1224.355683\n",
       "6     1224.356192\n",
       "7     1224.235349\n",
       "8     1224.216470\n",
       "9     1224.258288\n",
       "10    1224.143721\n",
       "11    1224.178955\n",
       "12    1224.133709\n",
       "13    1224.075160\n",
       "14    1224.135140\n",
       "15    1223.875479\n",
       "16    1223.893606\n",
       "17    1223.812248\n",
       "18    1223.782566\n",
       "19    1223.717322\n",
       "20    1223.529330\n",
       "21    1223.726450\n",
       "22    1223.720750\n",
       "23    1223.579304\n",
       "24    1223.529050\n",
       "25    1223.627680\n",
       "26    1223.454270\n",
       "27    1223.420681\n",
       "28    1223.326355\n",
       "29    1223.385662\n",
       "...           ...\n",
       "4970  1218.549393\n",
       "4971  1218.549386\n",
       "4972  1218.549393\n",
       "4973  1218.549381\n",
       "4974  1218.549386\n",
       "4975  1218.549385\n",
       "4976  1218.549386\n",
       "4977  1218.549372\n",
       "4978  1218.549380\n",
       "4979  1218.549392\n",
       "4980  1218.549380\n",
       "4981  1218.549387\n",
       "4982  1218.549392\n",
       "4983  1218.549388\n",
       "4984  1218.549388\n",
       "4985  1218.549382\n",
       "4986  1218.549388\n",
       "4987  1218.549376\n",
       "4988  1218.549381\n",
       "4989  1218.549389\n",
       "4990  1218.549375\n",
       "4991  1218.549390\n",
       "4992  1218.549386\n",
       "4993  1218.549389\n",
       "4994  1218.549384\n",
       "4995  1218.549390\n",
       "4996  1218.549389\n",
       "4997  1218.549385\n",
       "4998  1218.549389\n",
       "4999  1218.549385\n",
       "\n",
       "[5000 rows x 1 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Object `sin` not found.\n"
     ]
    }
   ],
   "source": [
    "?sin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000,)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.mean(axis=0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 2)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.random.randn(1000,dim_x)\n",
    "y_test = 50*np.array([np.sin(x_test.mean(axis=1)),np.cos(x_test.mean(axis=1))]).T + np.random.randn(1000, dim_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_test = net(x_test,w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = compute_loss(y_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1224.6446847290822"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
